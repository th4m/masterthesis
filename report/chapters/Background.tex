\chapter{Background}
Chapter~\ref{chapter:intro} shortly introduced the basics of lazy and strict
semantics. This chapter will present a more in-depth description of semantics
and compilers, as well as some previous work on the subject.

\section{Semantics}
Every programming language has its own \textit{semantics}. Semantics are often
informally explained in English prose, but some languages have formal semantics.
The semantics of a programming language defines
the meaning of programs~\cite{Fernand:PLangOpSem}.
In other words, the semantics of a language describes how programs are executed.
Different languages tend to use the same constructs, e.g. \texttt{if/else}, but
evaluate these constructs differently. This is where the semantics defines the
language.

The semantics of a language can be defined in different ways. The most
natural approach for the semantics of this project is
\textit{operational semantics}. FernÃ¡ndez states that operational semantics
is very useful for implementing languages and proving correctness of compiler
optimisations~\cite{Fernand:PLangOpSem}. By using operational
semantics, each construct is defined by computation steps. These steps are
often described with the help of transition systems, presenting the computation
steps as a sequence of transitions. For this project, however,
the operational semantics will be defined in the form of Haskell functions.
By defining the operational semantics as Haskell functions, it can be observed
and executed as Haskell code.

\subsection{Strict semantics}
Strict programming indicates that expressions are always fully evaluated when
they appear in the chain of evaluation. For example, when an arithmetic expression
is bound to a variable, the expression is fully evaluated to become a numerical
value before being assigned to the variable. The value is then accessible
by simply using the variable.

\subsection{Lazy semantics}
\label{back:lazySem}
The main characteristics of laziness is delaying evaluation of expressions
until they are needed. This is often done when binding expressions to
variables. In order to delay the evalution of an expression, lazy semantics
makes use of a data structure called
\textit{thunk}~\cite{Ennals:2003:OEA:944746.944731}. A thunk contains a
suspended expression together with information that is required to finish the
evaluation of the expression. Expressions that are to be
evaluated are suspended in so called thunk values and passed on correspondingly.
When needed, these thunks are \textit{forced} in order to yield an actual usable
value.
% Using this
%mechanic requires more memory usage than when evaluating with strict semantics.

\subsection{Pros and cons of both semantics}
One reason to why applications are programmed strictly is because it can be
necessary to have all values fully evaluated. If the evaluation of an expression
that is erroneous is delayed, the error that it will bring will also be delayed.
An example would be to consider a stateful system; if an operation is dependent
on a reference, the value assigned to that reference needs to have been
evaluated. If the evaluation of that value is delayed until after it is used,
an error is prone to occur, as that value may not be there.
By using strict evaluation, the evaluation is not delayed, avoiding any
ambiguity of knowing whether or not references will have valid values.

It is not always certain that all expressions that are contained in a program
will be used every time that it is executed. The more complex a program is, the
higher the chance is for branching. For example, a number of expressions may
be evaluated and bound to variables before a chain of
\texttt{if}/\texttt{else if} expressions. Certain branches of this program may
only use a select few, or even none, of the previously assigned variables.
In such cases, it would not be optimal to actually evaluate them.

Lazy evalution can be motivated with an opposite reason in relation to strict
evaluation. Programs that have a number of expressions bound to variables may
not make use of all of them. For example, when using the \texttt{case} construct
to pattern match in Haskell, the expression that is pattern matched can be
assigned to a variable as an effect of the pattern matching:

\begin{figure}[H]
\begin{alltt}
  case list of
    [] -> ...
    xs -> ...
\end{alltt}
\end{figure}

\noindent In the second case, \texttt{list} is assigned to the variable
\texttt{xs} as an effect of the pattern matching. For the pattern matching,
\texttt{list} is evaluated to check its outermost constructor. If it is an empty
list, it will be matched to the \texttt{[]} case, while the \texttt{xs} case
handles all other cases, where \texttt{list} is bound to the variable
\texttt{xs}. Further evaluation of
\texttt{list} is delayed until \texttt{xs} is used, meaning
that the actual content of list can be infinite in length without having the
evaluation of the program ending up in a non-terminating loop.

Infinite data structures are a major benefit for using lazy evaluation.
As described in Section~\ref{intro:Example}, the function \texttt{take}
in Haskell returns a subset of a given list. \texttt{take} has two arguments,
an integer \texttt{x} and a list \texttt{xs}. This is used to get the
\texttt{x} first elements of the list \texttt{xs}. The lazy evaluation of
\texttt{xs} in \texttt{take} allows the list to be infinite in size. This
can be used for a program that e.g. returns the first \texttt{x} elements of
the Fibonacci numbers.


\section{Compilers}
When a programmer has written code, the code must be translated into a form such
that it can be executed by a computer. This translation is the job of a
\textit{compiler}~\cite{DragonBook}. A compiler is a program that reads
programs in a \textit{source} language and translates it to a \textit{target}
language. The source language is often some high-level language, while the
target language is a low-level machine language.
For example, when compiling programs with Java as source language, the target
language that the compiler translates the code to is most likely Java Virtual
Machine (JVM)~\cite{JavaJVM}.

There exists a certain category of compilers that translates code from a
high-level language to another high-level language. This category of compilers
is often referred to as \textit{transpilers} or
\textit{source-to-source compilers}~\cite{kulkarnitranspiler}.
The goal of transpilers is to generate code in the target language that behaves
equivalently to the code in the source language. The compiler defined in this %Should this be here?
thesis can be considered to be of this category. In this case, the source
language is lazy CakeML and the target language is strict CakeML.

A common practice of compilers is to create an intermediate representation of
the input code in the form of constructors in a syntax
tree~\cite{DragonBook}. The intermediate representation needs to be
easy to produce and is used for optimising the code, as well as allowing for
easy generation of code in the target language.
For this project, the intermediate representation of CakeML expressions is %Should this be here?
written as abstract syntax trees (ASTs) in Haskell. The ASTs will be altered so
that when the target CakeML code is generated, it should be able to be evaluated
lazily, but with the use of the native CakeML semantics that evaluates strictly.

\section{CakeML}
\label{back:cakeml}
This section will present CakeML, the language that is the main focus of this
thesis. CakeML is a strict functional programming language that is based on a
subset of Standard ML~\cite{CakeML25:online}. Its semantics is defined in
higher-order logic (with HOL interactive theorem prover)~\cite{HOLInter57:online}
and its compiler is formally
proved to transform CakeML programs to semantically equivalent machine
code~\cite{Kumar:2014:CVI:2535838.2535841}.

The semantics provided for this project is specified in
Lem~\cite{Lem33:online,LemPaper}. Lem is a lightweight tool for creating
and handling large scale semantic definitions. It can also be used as an
intermediate language for porting definitions between interactive theorem proving
systems, such as HOL4.

This thesis presents a Haskell translation of the Lem definition of CakeML's
strict semantics, as well as a newly defined lazy semantics of CakeML. The
compiler that is the goal of the project draws inspiration from the lazy
semantics.

\section{Previous work}
This section will present and discuss previous work that is related to this
project. Topics include programming language libraries that allow lazy/strict
evaluation in languages that do not allow it by default, as well as an
evaluation strategy for Haskell that tries to optimise the inherent laziness
of the language.

\subsection{Libraries}
There are many languages that are strict that have additional libraries
containing lazy versions of primitive functions and vice versa. This section
will present some examples of languages with this type of functionality.

\subsubsection{Haskell}
Haskell is one of very few languages that are inherently lazy. All primitive
operations are lazy by nature, but the language also has certain functions that
enforce strict evaluation.

An example of a function that enforces strictness is
\texttt{seq}~\cite{seqHaske29:online}, which is a function that takes two
arguments: \texttt{a} and \texttt{b}, and returns \texttt{b}. The
result of \texttt{seq} is dependent on both \texttt{a} and \texttt{b}. If
\texttt{a} does not terminate, \texttt{seq} does not terminate. If \texttt{a}
does terminate, the result of \texttt{seq} is equal to \texttt{b}. While both
\texttt{a} and \texttt{b} are evaluated before returning the result,
\texttt{seq} does not guarantee that \texttt{a} is evaluated before \texttt{b}.

Haskell also has a function denoted as \texttt{\$!} that evaluates arguments strictly.
As arguments are normally evaluated lazily in Haskell, thunks are naturally
generated, often creating an overhead in the computation. When an argument is
known to always be evaluated, \texttt{\$!} is recommended to avoid unnecessary
suspensions~\cite{Performa16:online}.

\subsubsection{C\#}
C\# is an object oriented programming language developed by Microsoft. The
language is strict, but has a Class \texttt{Lazy<T>} that allows lazy
initialization~\cite{LazyTCla1:online}. The \texttt{Lazy<T>} class allows
lazy evaluation in a similar way as it is done in Haskell, as
function calls can be encapsulated for passing the call until it needs to be
evaluated~\cite{csharp}. The call only happens once, with the use of caching,
meaning that multiple uses will not cause multiple evaluations of the same
suspended function.


\subsection{Optimistic evaluation}

This section will present and discuss an evaluation strategy that was developed
for Haskell by Ennals and Peyton Jones~\cite{Ennals:2003:OEA:944746.944731}.
In their paper they state that they measure common usage of thunks. As lazy
evaluation creates an overhead with thunk utilization, programs can sometimes
evaluate slower in a lazy semantics than in a strict semantics. This led
them to create an evaluation strategy that makes use of their observation.
Strict evaluation makes use of call-by-value mechanics, where expressions are
always evaluated to values, while lazy evaluation uses call-by-need mechanics,
where thunks are exploited to delay the evaluation. The evaluation strategy
presented in the paper finds expressions that will always be evaluated, applying
call-by-value semantics on them, and uses an abortion mechanism for evaluation
that takes too long.

The results of the work showed that the tested set of programs was sped up by
a mean of about 15\%, while no program was slowed down with more than 15\%.
Thus, by dynamically choosing between call-by-value and call-by-name,
performance can be improved by a significant amount.
